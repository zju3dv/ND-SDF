desc: ""
train:
  exp_name: tnt_lowbatch
  max_step: 200000
  batch_size: 1 # image batch
  num_rays: 1024 # ray batch
  custom_sampling: true # enable deflection angle guided sampling

  dynamic_sampling: false # 训练时num_rays动态变化，伴随occupancy grid使用。
  max_num_rays: 8192
  num_samples_per_ray: 512

  log_freq: 10 # per step
  plot_freq: 100 # per epoch
  save_freq: 100
  chunk: 1024
  mesh_resolution: 512 # intermediate mesh resolution
  block_resolution: 512

  train_downscale: 1 # downscale factor for training
  valid_downscale: 1 # downscale factor for validation per plot_freq

dataset:
  scan_id: '1' # id=-1 for custom dataset in data_dir
  data_dir: data/tnt_advanced
  num_images: 303

  use_mono_depth: true  # apply monocular depth prior
  use_mono_normal: true  # apply monocular normal prior
  use_mask: false
  use_uncertainty: false

  use_pts: false


model:
  type: volsdf # 'neus' or 'volsdf'
  bound: 1.0
  white_bg: false
  density:
    # volsdf
    beta_init: 0.1
    beta_min: 1e-4

    # neus
    inv_s_init: 0.3
    scale_factor: 10.0
  object:
    sdf:
      d_in: 3
      d_hidden: 256
      n_layers: 2
      skip: [4]
      geometric_init: true
      bias: 0.9
      norm_weight: true
      inside_outside: true  # default outside for object

      enable_fourier: true # fourier
      N_freqs: 7

      enable_hashgrid: true # hashgrid
      num_levels: 16
      per_level_dim: 2
      log2_hashmap_size: 19
      base_resolution: 16
      max_resolution: 2048
      resolution_list: None

      # Neuralangelo
      enable_progressive: true
      init_active_level: 8
      active_step: 2000
      gradient_mode: numerical # analytical or numerical
      taps: 4

    rgb:
      feat_dim: 256  # sdf feature dim
      d_hidden: 256
      n_layers: 2
      skip: []
      N_freqs: 3
      encoding_view: spherical  # 'fourier' or 'spherical'
      weight_norm: true
      layer_norm: false
      enable_app: true # appearance embedding
      app_dim: 32

  background:
    enabled: false
    type: 'grid_nerf' # "nerf++" or "grid_nerf" background model
    enable_app: false
    app_dim: 8
    nerf_plus_plus: # NeRF++: inverse spherical reparameterization
      d_hidden: 64
      n_layers: 4 # 到density的层数
      skip: [ 4 ]  # density network
      d_hidden_rgb: 64
      n_layers_rgb: 2
      skip_rgb: [ ]
      encoding: fourier
      N_freqs: 10
      encoding_view: spherical
      N_freqs_view: 4
    grid_nerf: # grid_nerf：Mip-Nerf 360 and light hash grid encoding
      d_hidden: 64
      n_layers: 2
      skip: []  # 1-n_layers
      d_hidden_rgb: 64
      n_layers_rgb: 2
      skip_rgb: []
      norm_weight: true

      # position encoding
      enable_fourier: true # fourier
      N_freqs: 6
      enable_hashgrid: true # hashgrid
      num_levels: 16
      per_level_dim: 2
      log2_hashmap_size: 19
      base_resolution: 16
      max_resolution: 2048
      resolution_list: None

      enable_progressive: true
      init_active_level: 4
      active_step: 2000

      # view encoding
      encoding_view: spherical
      N_freqs_view: 4

  # default error bounded sampler
  sampler:
    error_bounded_sampler:
      near: 0.
      N_samples: 64
      N_samples_eval: 256
      N_samples_extra: 32
      N_samples_bg: 32
      N_near: 1
      eps: 0.1
      beta_iters: 10
      max_total_iters: 5
      take_intersection: true
      intersection_type: cube # 'cube' or 'sphere'
    hierarchical_sampler:
      near: 0.
      N_samples_c: 64
      N_samples_f: 16
      N_samples_bg: 32
      N_near: 1
      levels: 4
      take_intersection: true
      intersection_type: sphere # 'cube' or 'sphere'

  occupancy: # occupancy grid acceleration using nerfacc
    enabled: false
    resolution: 128
    prune_threshold: 0.001
    dynamic_step: false

  occupancy_bg:
    enabled: false
    resolution: 256
    prune_threshold: 0.01

  # The Normal Deviation Field
  # FIXME and TODO：We observe the deviations are unstable in the training process. Plan to manually schedule the learning rate for the normal deviation field.
  nbfield:
    enabled: true
    mlp:
      feat_dim: 256
      d_hidden: 256
      n_layers: 2
      skip: []
      N_freqs: 4
      encoding_view: fourier  # 'fourier' or 'spherical'
      weight_norm: true
      layer_norm: false
      enable_app: true
      app_dim: 8
loss:
  # loss format supports sequential_lr: [start_prog, end_prog, start_lr, end_lr]
  lambda_rgb_l1: 1.0
  lambda_rgb_mse: 0.0
  lambda_s3im: [0.5,1,0.05,0.05] # FIXME: we recommend to use s3im loss in the last stage of training, this facilitates more details. We did not use it in the paper.
  lambda_eik: 0.05 # eikonal loss
  lambda_smooth: 0.005 # smooth loss from monosdf
  lambda_normal: 0.0 # naive normal loss
  lambda_depth: 0.0 # naive depth loss
  lambda_curvature: 5e-4 # curvature loss
  lambda_ab_normal: 0.015 # adaptive deflection angle normal loss
  lambda_ab_depth: 0.03 # aadaptive deflection angle depth loss

optim:
  type: AdamW
  lr: 2.5e-4
  lr_scale_grid: 20.0
  lr_scale_density: 1.0
  sched:
    type: exponential_lr # 'two_steps_lr' or 'exponential_lr'
    gamma: 0.1
    two_steps: [300000, 400000] # two steps lr decay
    warm_up_end: 2000 # warm up steps

    anneal_quat_end: 0.2 # percent of total steps to warm up, then start sampling, re-weighting, and unbiasing.
    if_guided_sampling: true
    guided_sampling_params: [ 25, 15, 4 ]
    if_reweight: true
    re_weight_params: [ 25, 15, 2 ]
    if_unbiased: true
    unbiased_params: [ 25,10 ]